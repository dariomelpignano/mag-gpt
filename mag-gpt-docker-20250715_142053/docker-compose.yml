version: '3.8'

services:
  mag-gpt:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mag-gpt-app
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - LM_STUDIO_BASE_URL=${LM_STUDIO_BASE_URL:-http://192.168.97.3:5002}
      - LM_STUDIO_EMBEDDINGS_MODEL=${LM_STUDIO_EMBEDDINGS_MODEL:-text-embedding-nomic-embed-text-v2-moe}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET:-your-super-secret-key-change-this}
      - NEXTAUTH_URL=${NEXTAUTH_URL:-http://localhost:3000}
      # User authentication (add more as needed)
      - USER_colleague_company_com=${USER_COLLEAGUE_PASSWORD:-defaultpassword}
      - USER_admin_company_com=${USER_ADMIN_PASSWORD:-adminpassword}
    volumes:
      # Optional: Persist uploaded files and cache
      - ./data/uploads:/app/uploads
      - ./data/cache:/app/.next/cache
    networks:
      - mag-gpt-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/models"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: mag-gpt-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deployment/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deployment/ssl:/etc/nginx/ssl:ro
    depends_on:
      - mag-gpt
    networks:
      - mag-gpt-network

networks:
  mag-gpt-network:
    driver: bridge

volumes:
  mag-gpt-data:
    driver: local 